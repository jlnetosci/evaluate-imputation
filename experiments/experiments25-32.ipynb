{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689c913d-fd49-4492-ba9f-3a808dbba2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocess import Pool\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85be377e-f753-4a70-ac36-59032da7a567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1a9881019f4acb84b8fab27e5873c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13e7b8cff04487880d0e55d25b0b343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-4:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/multiprocess/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m num_processors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;66;03m# Adjust this value based on your CPU core count\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(num_processors) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 81\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Create the dictionary of dataframes\u001b[39;00m\n\u001b[1;32m     84\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i): df \u001b[38;5;28;01mfor\u001b[39;00m i, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results)}\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/multiprocess/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment_list = [25, 26, 27, 28, 29, 30, 31, 32]\n",
    "n_features_list = [10, 10, 10, 12, 10, 12, 12, 12]\n",
    "n_sample_list = [100, 100, 1000, 100, 1000, 100, 1000, 1000]\n",
    "max_value_list = [100, 1000, 100, 100, 1000, 1000, 100, 1000]\n",
    "\n",
    "for q in tqdm(range(len(experiment_list))):\n",
    "    # Set random seed for reproducibility (optional)\n",
    "    np.random.seed(20230801)\n",
    "\n",
    "    # Generate synthetic dataset\n",
    "    num_samples = n_sample_list[q]\n",
    "    num_features = n_features_list[q]\n",
    "\n",
    "    # Define the range for the random values\n",
    "    low = 0\n",
    "    high = max_value_list[q]\n",
    "\n",
    "    # Create a dictionary to store the data\n",
    "    data = {}\n",
    "    for feature_num in range(1, num_features + 1):\n",
    "        data[f'Feature{feature_num}'] = np.random.uniform(low, high, num_samples)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    syn = pd.DataFrame(data)\n",
    "\n",
    "    num_samples = 1\n",
    "    #num_features = 10\n",
    "\n",
    "    #low = 0\n",
    "    #high = 100\n",
    "\n",
    "    combs = []\n",
    "    for i in range(len(syn) + 1):\n",
    "        combs += [list(comb) for comb in combinations(syn, i)]\n",
    "    combs = [comb for comb in combs if len(comb) >= 1]\n",
    "\n",
    "    # Preprocessing: Fit the StandardScaler to the synthetic dataset\n",
    "    scaler = StandardScaler()\n",
    "    scaled_syn = pd.DataFrame(scaler.fit_transform(syn), columns=syn.columns)\n",
    "\n",
    "    # Function to compute Nearest Neighbors for a given combination\n",
    "    def compute_neighbors(seed):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Create a dictionary to store the data\n",
    "        data = {}\n",
    "        for feature_num in range(1, num_features + 1):\n",
    "            data[f'Feature{feature_num}'] = np.random.uniform(low, high, num_samples)\n",
    "\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        query = pd.DataFrame(data)\n",
    "\n",
    "        scaled_query = pd.DataFrame(scaler.transform(query), columns=query.columns)\n",
    "\n",
    "        length_list = []; nn_list = []; distance_list = []\n",
    "\n",
    "        for comb in combs:\n",
    "            length_list.append(len(comb))\n",
    "            # Create a NearestNeighbors object and fit the data\n",
    "            nbrs = NearestNeighbors(n_neighbors=1).fit(scaled_syn[comb])\n",
    "\n",
    "            # Find the nearest neighbor\n",
    "            distances, indices = nbrs.kneighbors(scaled_query[comb])\n",
    "\n",
    "            # Print the nearest neighbor's index and distance\n",
    "            nn_list.append(indices[0][0])\n",
    "            distance_list.append(distances[0][0])\n",
    "\n",
    "        experiment = {\n",
    "            'n_features': length_list,\n",
    "            'index': nn_list,\n",
    "            'distance': distance_list\n",
    "        }\n",
    "\n",
    "        var = pd.DataFrame(experiment)\n",
    "        return var\n",
    "\n",
    "    # Use multiprocessing to parallelize the loop\n",
    "    num_processors = 4 # Adjust this value based on your CPU core count\n",
    "    with Pool(num_processors) as pool:\n",
    "        results = list(tqdm(pool.imap(compute_neighbors, range(0, 1000)), total=1000))\n",
    "\n",
    "    # Create the dictionary of dataframes\n",
    "    d = {\"df\" + str(i): df for i, df in enumerate(results)}\n",
    "    \n",
    "    # Pickle the dictionary and save it to a file\n",
    "    with open('data_frames_experiment' + str(experiment_list[q]) + '_' + str(n_features_list[q]) + 'features_' + str(n_sample_list[q]) + 'samples_' + str(max_value_list[q]) + 'vals.obj', 'wb') as f:\n",
    "        pickle.dump(d, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
